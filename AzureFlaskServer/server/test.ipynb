{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Tuple, List, Optional, Dict, Literal\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "chains = Chains(llm)\n",
    "\n",
    "chain = chains.get_initial_check_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BooleanOutputParser(ai_message: AIMessage) -> bool:\n",
    "      \"\"\"\n",
    "      Parses the AI message to determine if the answer is a yes or no\n",
    "      \"\"\"\n",
    "      if 'yes' in ai_message.lower():\n",
    "          return True\n",
    "      else:\n",
    "          return False\n",
    "    \n",
    "def get_initial_check_chain(llm):\n",
    "    \"\"\"\n",
    "    Returns the initial check chain\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                You can only answer questions with a yes or no\n",
    "                \"\"\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                Does the following text contains a non-genric entity that needs to be elaborated on?\n",
    "\n",
    "                Text: {text}\n",
    "                \"\"\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser() | BooleanOutputParser\n",
    "    return chain\n",
    "\n",
    "def get_elaboration_chain(llm):\n",
    "    \"\"\"\n",
    "    Returns the elaboration chain\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                You are a master at elaborating on non-generic entities.\n",
    "                \"\"\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                Identify the non-generic entity in the following text and elaborate on it.\n",
    "\n",
    "                Text: {text}\n",
    "                \"\"\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = get_initial_check_chain(llm)\n",
    "chain.invoke({\"text\":\"test\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_chain():\n",
    "\n",
    "    # Define the ChatPromptTemplate for condensing the list of payroll items\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                You can only answer questions with a yes or no\n",
    "                \"\"\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                Does the following text contains a non-genric entity that needs to be elaborated on?\n",
    "\n",
    "                Text: {text}\n",
    "                \"\"\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define the condenser_chain\n",
    "    condenser_chain = prompt | llm | StrOutputParser() | BooleanOutputParser\n",
    "\n",
    "    return condenser_chain\n",
    "\n",
    "# Define the test_condenser function\n",
    "def test_condenser():\n",
    "    condenser_chain = test_chain()\n",
    "    response = condenser_chain.invoke({\"text\":\"test\"})\n",
    "    print(response)\n",
    "    \n",
    "\n",
    "\n",
    "test_condenser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
