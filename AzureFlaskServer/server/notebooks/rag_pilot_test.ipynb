{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Displaying final output format\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "# Langchain Dependencies\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langgraph.graph import END, StateGraph\n",
    "# For State Graph \n",
    "from typing_extensions import TypedDict\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.runnables import (\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Tuple, List, Optional\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "from langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\n",
    "\n",
    "from utils import CSVAgentGPTInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "llm_json = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, model_kwargs={\"response_format\": {\"type\": \"json_object\"}})\n",
    "\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'general'}\n"
     ]
    }
   ],
   "source": [
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(),\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, object, location, or event entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting person, object, location, or event entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "entity_chain = prompt | llm.with_structured_output(Entities)\n",
    "\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a full-text search query for a given input string.\n",
    "\n",
    "    This function constructs a query string suitable for a full-text search.\n",
    "    It processes the input string by splitting it into words and appending a\n",
    "    similarity threshold (~2 changed characters) to each word, then combines\n",
    "    them using the AND operator. Useful for mapping entities from user questions\n",
    "    to database values, and allows for some misspelings.\n",
    "    \"\"\"\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()\n",
    "\n",
    "# Fulltext index query\n",
    "def structured_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"\n",
    "            CALL db.index.fulltext.queryNodes('entity', $query, {limit: 2})\n",
    "            YIELD node, score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' + node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result\n",
    "\n",
    "def retriever(question: str):\n",
    "    structured_data = structured_retriever(question)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
    "    final_data = f\"\"\"Structured data:\n",
    "        {structured_data}\n",
    "        Unstructured data:\n",
    "        {\"#Document \". join(unstructured_data)}\n",
    "    \"\"\"\n",
    "    return final_data\n",
    "\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n",
    "in its original language.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"  # noqa: E501\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer\n",
    "\n",
    "_search_query = RunnableBranch(\n",
    "    # If input includes chat_history, we condense it with the follow-up question\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "            run_name=\"HasChatHistoryCheck\"\n",
    "        ),  # Condense follow-up question and chat into a standalone_question\n",
    "        RunnablePassthrough.assign(\n",
    "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        )\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | ChatOpenAI(temperature=0)\n",
    "        | StrOutputParser(),\n",
    "    ),\n",
    "    # Else, we have no chat history, so just pass through the question\n",
    "    RunnableLambda(lambda x : x[\"question\"]),\n",
    ")\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Use natural language and be as elaborate as possible.\n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": _search_query | retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def invoke_chain(question: str, chat_history):\n",
    "    graph.query(\n",
    "        \"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n",
    "    if chat_history:\n",
    "        return chain.invoke(\n",
    "            {\n",
    "                \"question\": question,\n",
    "                \"chat_history\": chat_history\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return chain.invoke(\n",
    "            {\n",
    "                \"question\": question,\n",
    "            }\n",
    "        )\n",
    "    \n",
    "\n",
    "# Router\n",
    "router_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an expert at routing a user question to either the generation stage or general query stage. \n",
    "    Use the general query for questions that does not require additional contextual information.\n",
    "    Otherwise, you can skip and go straight to the generation phase to respond.\n",
    "    You do not need to be stringent with the keywords in the question related to these topics.\n",
    "    Give a binary choice 'general' or 'generate' based on the question. \n",
    "    Return the JSON with a single key 'choice' with no premable or explanation. \n",
    "    \n",
    "    Question to route: {question} \n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "question_router = router_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# Test Run\n",
    "question = \"What's up?\"\n",
    "print(question_router.invoke({\"question\": question}))\n",
    "\n",
    "# General chain\n",
    "general_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an expert at answering general questions. \n",
    "    Use the general query for questions that does not require additional contextual information.\n",
    "    You do not need to be stringent with the keywords in the question related to these topics.\n",
    "    Answer the following question in a natural language. \n",
    "    \n",
    "    Question: {question} \n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "general_chain = general_prompt | llm | StrOutputParser()\n",
    "\n",
    "  \n",
    "############################################################# Graph State #############################################################\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        search_query: revised question for web search\n",
    "        context: web_search result\n",
    "    \"\"\"\n",
    "    question : str\n",
    "    generation : str\n",
    "    search_query : str\n",
    "    context : str\n",
    "\n",
    "# Node - Generate\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Step: Generating Final Response\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Answer Generation\n",
    "    generation = invoke_chain(question, None)\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "def general(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Step: Generating Final Response\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Answer Generation\n",
    "    generation = general_chain.invoke({\"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "# Conditional Edge, Routing\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    route question to web search or generation.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Step: Routing Query\")\n",
    "    question = state['question']\n",
    "    output = question_router.invoke({\"question\": question})\n",
    "    if output['choice'] == \"general\":\n",
    "        print(\"Step: Routing Query to General\")\n",
    "        return \"general\"\n",
    "    elif output['choice'] == 'generate':\n",
    "        print(\"Step: Routing Query to Generation\")\n",
    "        return \"generate\"\n",
    "    \n",
    "def build_workflow():\n",
    "    \"\"\"\n",
    "    Build the workflow for the graph\n",
    "    \"\"\"\n",
    "    # Build the nodes\n",
    "    workflow = StateGraph(GraphState)\n",
    "    workflow.add_node(\"general\", general)\n",
    "    workflow.add_node(\"generate\", generate)\n",
    "\n",
    "    # Build the edges\n",
    "    workflow.set_conditional_entry_point(\n",
    "        route_question,\n",
    "        {\n",
    "            \"general\": \"general\",\n",
    "            \"generate\": \"generate\",\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"general\", END)\n",
    "    workflow.add_edge(\"generate\", END)\n",
    "\n",
    "    # Compile the workflow\n",
    "    local_agent = workflow.compile()\n",
    "\n",
    "    return local_agent\n",
    "\n",
    "def run_agent(query, local_agent):\n",
    "    output = local_agent.invoke({\"question\": query})\n",
    "    print(\"=======\")\n",
    "    display(Markdown(output[\"generation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n",
      "Step: Routing Query to Generation\n",
      "Step: Generating Final Response\n",
      "=======\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but without any specific information or data provided in the context, I am unable to answer the question about how many sales TikTok made yesterday. TikTok is a popular social media platform, but without structured data or specific details about their sales figures, it is impossible to provide an accurate answer. It would be necessary to have access to TikTok's financial reports or sales data to determine the number of sales they made on a specific day."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test it out!\n",
    "agent = build_workflow()\n",
    "run_agent(\"How many sales did TikTok make yesterday?\", agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "llm_json = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, model_kwargs={\"response_format\": {\"type\": \"json_object\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "added actions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_list = [\n",
    "  {\n",
    "    \"database_name\": \"Sales_database123\",\n",
    "    \"database_description\": \"A database that contains information about supermarket sales.\",\n",
    "    'columns': \"Invoice ID, Product ID, Shop ID, Customer ID, Date, Time, Payment, Unit Price, Quantity, Total Price\",\n",
    "    \"database_path\": \"../csv_db/supermarket_sales_db.csv\",\n",
    "  },\n",
    "  {\n",
    "    \"database_name\": \"Outlet_database\",\n",
    "    \"database_description\": \"A database that contains information about physical outlets.\",\n",
    "    \"columns\": \"Shop ID, Country, City, State, Shop Name, Shop Type, Shop Size, Address\",\n",
    "    \"database_path\": \"../csv_db/shop_outlet_db.csv\",\n",
    "  },\n",
    "  {\n",
    "    \"database_name\": \"Customer_database\",\n",
    "    \"database_description\": \"A database that contains information about customers.\",\n",
    "    \"columns\": \"Customer ID, Customer Name, Customer Email, Customer Phone, Customer Address, Gender, Age\",\n",
    "    \"database_path\": \"../csv_db/customer_db.csv\",\n",
    "  },\n",
    "  {\n",
    "    \"database_name\": \"Product_database\",\n",
    "    \"database_description\": \"A database that contains information about products.\",\n",
    "    \"columns\": \"Product ID, Product Name, Product Price, Product Category\",\n",
    "    \"database_path\": \"../csv_db/product_db.csv\",\n",
    "  },\n",
    "]\n",
    "\n",
    "actions_list = [\n",
    "  {\n",
    "    \"action_type\": \"query_database\",\n",
    "    \"action_name\": \"most_product_sales_for_shop\",\n",
    "    \"action_description\": \"Search for which product had the most sales from a specific shop.\",\n",
    "    \"input\": [\"sales\", \"shop name\",],\n",
    "    \"output\": [\"product name\", \"product ID\",],\n",
    "  },\n",
    "  {\n",
    "    \"action_type\": \"query_database\",\n",
    "    \"action_name\": \"most_customer_sales_for_shop\",\n",
    "    \"action_description\": \"Search for which customer had the most sales from a specific shop.\",\n",
    "    \"input\": [\"sales\", \"shop name\",],\n",
    "    \"output\": [\"customer name\", \"customer ID\",],\n",
    "  },\n",
    "  {\n",
    "    \"action_type\": \"query_database\",\n",
    "    \"action_name\": \"full_description_of_product\",\n",
    "    \"action_description\": \"Give the full description of a product.\",\n",
    "    \"input\": [\"product name\",],\n",
    "    \"output\": [\"product ID\", \"product name\", \"product price\", \"product category\",],\n",
    "  },\n",
    "  {\n",
    "    \"action_type\": \"api_call\",\n",
    "    \"action_name\": \"create_jira_issue\",\n",
    "    \"action_description\": \"Creates a Jira Issue with the given details.\",\n",
    "    \"input\": [\"issue title\", \"issue description\", \"issue type\", \"issue priority\",],\n",
    "    \"output\": [],\n",
    "  },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "added chain to identify which action to select\n",
    "\n",
    "few shot dont work for actions for some reason ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### DB Routing ######################\n",
    "\n",
    "example_db_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "      (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        Database name: {database_name}\n",
    "        Database description: {database_description}\n",
    "        Database columns: {columns}\n",
    "        \"\"\",\n",
    "      ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "db_few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "  example_prompt=example_db_prompt,\n",
    "  examples=database_list,\n",
    ")\n",
    "\n",
    "db_router_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      You are a expert at routing a user query to one of the database provided below. \n",
    "      Your choice should be one of the database's name. \n",
    "      You can return NA if the query is not related to any of the databases.\n",
    "      Return the JSON with a single key 'choice' with no premable or explanation.\n",
    "\n",
    "      Choices:\n",
    "      \"\"\"\n",
    "    ),\n",
    "    db_few_shot_prompt,\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "      \"Query: {query}\"\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "multi_db_router_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      You are a expert at routing a user query to the database provided below. \n",
    "      You can select more than one database if the query requires information from multiple databases.\n",
    "      Your choices should be the database's name. \n",
    "      You can return NA if the query is not related to any of the databases.\n",
    "      You should return a list of database names.\n",
    "      Return the JSON with a single key 'choice' with no premable or explanation.\n",
    "\n",
    "      Choices:\n",
    "      \"\"\"\n",
    "    ),\n",
    "    db_few_shot_prompt,\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "      \"Query: {query}\"\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "###################### Choose Which Action ######################\n",
    "\n",
    "choose_action_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      You are an intelligent assistant. \n",
    "      Your task is to match a user's query to a list of actions based on the inputs required for each action. \n",
    "      Each action has a specific set of inputs that it requires. \n",
    "      You should identify which actions can be taken based on the inputs mentioned in the user's query and return those actions in JSON format.\n",
    "      Return NA if and only if the query is not related to any of the actions.\n",
    "      You should return a list of action names.\n",
    "      Return the JSON with a single key 'name' with no premable or explanation.\n",
    "\n",
    "      Choices:\n",
    "      \"\"\"\n",
    "    ),\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "            \"\\n\".join(\n",
    "                [\n",
    "                    f\"\"\"\n",
    "                    Action type: {action['action_type']}\n",
    "                    Action name: {action['action_name']}\n",
    "                    Action description: {action['action_description']}\n",
    "                    Action input: {action['input']}\n",
    "                    Action output: {action['output']}\n",
    "                    \"\"\"\n",
    "                    for action in actions_list\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "      \"Query: {query}\"\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "###################### Generate Prompt from Action Prompt ######################\n",
    "\n",
    "# Few Shot Chat Message Prompt Template\n",
    "generate_prompt_from_action_prompt_examples = [\n",
    "  {\n",
    "    \"query\": \"Summarize the sales for Shop A.\",\n",
    "    \"action_description\": \"Search for which product had the most sales from a specific shop.\",\n",
    "    \"action_input\": [\"sales\", \"shop name\"],\n",
    "    \"action_output\": [\"product name\", \"product ID\"],\n",
    "    \"answer\": \"First, give me the name of the product that had the most sales from Shop A. Then, use that product name to find the product ID.\"\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Summarize the sales for Shop A.\",\n",
    "    \"action_description\": \"Search for which customer had the most sales from a specific shop.\",\n",
    "    \"action_input\": [\"sales\", \"shop name\"],\n",
    "    \"action_output\": [\"customer name\", \"customer ID\"],\n",
    "    \"answer\": \"First, give me the name of the customer that bought the most items from Shop A. Then, use that customer name to find the customer ID.\"\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Summarize the sales for Country A.\",\n",
    "    \"action_description\": \"Search for the city which had the highest quantity of items sold in a specific country.\",\n",
    "    \"action_input\": [\"sales\", \"country name\"],\n",
    "    \"action_output\": [\"city name\", \"quantity\"],\n",
    "    \"answer\": \"First, give me the city name which had the highest quantity of items sold in Country A. Then, give me the total quantity of items sold for that city.\"\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Give report on Customer A.\",\n",
    "    \"action_description\": \"Give the full details of a customer.\",\n",
    "    \"action_input\": [\"customer name\"],\n",
    "    \"action_output\": [\"customer ID\", \"customer name\", \"customer email\", \"customer phone\", \"customer address\", \"gender\", \"age\"],\n",
    "    \"answer\": \"Give me the customer ID, customer name, customer email, customer phone, customer address, gender, age of customer A.\"\n",
    "  }\n",
    "]\n",
    "\n",
    "generate_prompt_from_action_prompt_example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "      (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        Query: {query}\n",
    "        Action description: {action_description}\n",
    "        Action input: {action_input}\n",
    "        Action output: {action_output}\n",
    "        Answer: {answer}\n",
    "        \"\"\",\n",
    "      ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "generate_prompt_from_action_prompt_fewshotprompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=generate_prompt_from_action_prompt_examples,\n",
    "    example_prompt=generate_prompt_from_action_prompt_example_prompt,\n",
    ")\n",
    "\n",
    "# Prompt to generate systematic and precise output\n",
    "generate_prompt_from_action_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"      \n",
    "      You are an intelligent assistant. Your task is to create systematic and precise prompts to be fed to another llm,\n",
    "      based on a user's query and a list of actions.\n",
    "      Each action has a specific set of inputs and outputs. You should first identify the main action from the query.\n",
    "      Then, generate instructions that use intermediate results precisely.\n",
    "      Generate the step-by-step instructions using the action's inputs and outputs,\n",
    "      ensuring intermediate results are clearly stated and used in subsequent steps.\n",
    "      \"\"\"\n",
    "    ),\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      For the action:\n",
    "      Action description: {action_description}\n",
    "      Action input: {action_input}\n",
    "      Action output: {action_output}\n",
    "\n",
    "      Based on the query: \"{query}\", generate the output based on the action and the query.\n",
    "      \n",
    "      I will provide some examples to help you understand the task.\n",
    "      \n",
    "      Examples:\n",
    "\n",
    "      \"\"\"\n",
    "    ),\n",
    "    generate_prompt_from_action_prompt_fewshotprompt,\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      Do not include any explanation or preamble. Only return the actual answer.\n",
    "      \n",
    "      Return the answer as a string in natural language, in prose, with no bullet points, point form, or list format.\n",
    "      \"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "      \"Query: {query}\",\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "###################### Generate Final Output From Actions and Query ######################\n",
    "example_db_output = [\n",
    "  \"The product that had the most sales from Singapore Outlet 1 is 'Eau de Toilette' with the product ID 'ES41'\",\n",
    "  \"The customer that bought the most items from Singapore Outlet 1 is 'John Doe' with the customer ID 'JD123'\",\n",
    "]\n",
    "final_output_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      You are an intelligent assistant. \n",
    "      Your task is to answer the user's query using the context provided below. \n",
    "      If you don't know the answer, just say that you don't know.\n",
    "      Use natural language and elaborate meaningfully and provide suggestions for improvement when appropriate.\n",
    "\n",
    "      Context:\n",
    "      \"\"\"\n",
    "      +\"\\n\".join(\n",
    "          [\n",
    "            f\"\"\"\n",
    "            {cont}\n",
    "            \"\"\"\n",
    "            for cont in example_db_output\n",
    "          ]\n",
    "      )\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "      \"Query: {query}\"\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "###################### Generate Prompt for Extract Input for API Type Action ######################\n",
    "example_action = {\n",
    "    \"action_type\": \"api_call\",\n",
    "    \"action_name\": \"create_jira_issue\",\n",
    "    \"action_description\": \"Creates a Jira Issue with the given details.\",\n",
    "    \"input\": [\"issue title\", \"issue description\", \"issue type\", \"issue priority\",],\n",
    "    \"output\": [],\n",
    "  }\n",
    "api_extract_input_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      You are an expert at extracting information from a user query for input parameter of an API call. \n",
    "      Your task is to extract each input parameter for the API call from the user query.\n",
    "      The action, its description and the input parameters are provided below.\n",
    "      Return the JSON with the input as the keys with no premable or explanation.\n",
    "      Do not alter the input parameter names in any way when used as the key.\n",
    "      You should leave the value empty if the input parameter is not present in the query.\n",
    "\n",
    "      Action:\n",
    "\n",
    "      Action name: {action_name}\n",
    "      Action description: {action_desc}\n",
    "      Action input: {action_input}\n",
    "      \"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "      \"Query: {query}\"\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "###################### Generate General Response ######################\n",
    "general_response_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an intelligent agent, with the name Waffles Copilot.\n",
    "        Your role is to give general answers to questions that are not related to CRM related tasks or actions.\n",
    "\n",
    "        You should follow these specific guidelines to answering:\n",
    "\n",
    "        1. **Non-CRM Related Queries:**\n",
    "            - If a user asks a question that is unrelated to CRM processes (e.g., \"What is the weather today?\" or \"What is the Nvidia share price today?\"), \n",
    "            respond with a general-purpose message to redirect the user back to CRM-related tasks.\n",
    "\n",
    "        2. **General Purpose or Personal Queries:**\n",
    "            - If a user asks about your purpose or general well-being (e.g., \"Hi, what is your purpose?\" or \"How are you doing today?\"), respond with your purpose and role. \n",
    "            \n",
    "        3. **Hateful Queries:**\n",
    "          - If the user provides any hateful message or expresses inappropriate emotion (e.g., \"You suck\" or \"You are useless'), respond with a message that you acknowledge their feelings but you cannot answer such questions or that the question is inappropriate,\n",
    "          and redirect the user back to CRM-related tasks.\n",
    "        \n",
    "        4. **Inappropriate Queries:**\n",
    "          - If the user provides any inappropriate message (for example, racially insensitive, sexually explicit, violent, politically sensitive, etc), \n",
    "          (e.g., \"I hate all people from this country\" or \"I want to kill someone\" or \"I hate this political party\"),\n",
    "          respond with a message that you cannot answer such questions and redirect the user back to CRM-related tasks.\n",
    "          \n",
    "        5. **Non-English Queries:**\n",
    "          - If the user asks a question in a language other than English, respond with a message that you can only understand and respond to questions in English.\n",
    "\n",
    "        Remember, your main role is to assist with CRM processes and enhance the user's customer management experience.\n",
    "        \"\"\"\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "        \"Query: {query}\"\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_router_chain = db_router_prompt | llm | JsonOutputParser()\n",
    "multi_db_router_chain = multi_db_router_prompt | llm | JsonOutputParser()\n",
    "action_router_chain = choose_action_prompt | llm | JsonOutputParser()\n",
    "generate_prompt_from_action_prompt_chain = generate_prompt_from_action_prompt | llm | StrOutputParser()\n",
    "final_output_chain = final_output_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'issue title': 'Bug in the system',\n",
       " 'issue description': 'There is a bug in the system',\n",
       " 'issue type': '',\n",
       " 'issue priority': ''}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_extract_input_chain.invoke({\n",
    "  \"query\": \"Create a Jira issue with the title 'Bug in the system', description 'There is a bug in the system'\",\n",
    "  \"action_name\": example_action['action_name'],\n",
    "  \"action_desc\": example_action['action_description'],\n",
    "  \"action_input\": str(example_action['input'])\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In summary, the product 'Eau de Toilette' with the product ID 'ES41' had the most sales at Singapore Outlet 1. Additionally, the customer 'John Doe' with the customer ID 'JD123' bought the most items from this outlet. This information provides insight into the top-selling product and customer at Singapore Outlet 1. If you need more detailed information or specific data regarding sales at this outlet, feel free to ask for further details.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output_chain.invoke({\"query\": \"Summarize the sales for Singapore Outlet 1.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choice': ['Sales_database123', 'Customer_database']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_db_router_chain.invoke({\"query\": \"What is the name of the customer that made the biggest purchase?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test action router chain. Preliminary testing seems good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['most_product_sales_for_shop', 'most_customer_sales_for_shop']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_router_chain.invoke({\"query\": \"Summarize the sales for Singapore Outlet 1.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['create_jira_issue']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_router_chain.invoke({\"query\": \"Create a Jira Issue with the title 'Bug in the system' and description 'The system is not responding'.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one below seems inconsistent between NA and most_product_sales_for_shop??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['most_product_sales_for_shop']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_router_chain.invoke({\"query\": \"give me the city name with the highest quantity of items sold for Kuala Lumpur\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test generate action prompt. Seems good for the example_action_list given above also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_type': 'query_database', 'action_name': 'full_description_of_product', 'action_description': 'Give the full description of a product.', 'input': ['product name'], 'output': ['product ID', 'product name', 'product price', 'product category']}\n",
      "Give me the product ID, product name, product price, and product category of the product named Eau de Toilette.\n"
     ]
    }
   ],
   "source": [
    "test_action_1 = actions_list[2]\n",
    "print(test_action_1)\n",
    "\n",
    "response = generate_prompt_from_action_prompt_chain.invoke({\n",
    "    \"action_description\": test_action_1[\"action_description\"],\n",
    "    \"action_input\": test_action_1[\"input\"],\n",
    "    \"action_output\": test_action_1[\"output\"],\n",
    "    \"query\": \"Summarize product Eau de Toilette\",\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'most_product_sales_for_shop'}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "actions_chosen = action_router_chain.invoke({\"query\": \"Summarize the sales for Singapore Outlet 1.\"})\n",
    "print(actions_chosen)\n",
    "\n",
    "selected_actions_prompts = []\n",
    "query = \"Summarize the sales for Singapore Outlet 1.\"\n",
    "\n",
    "# Retrieve objects that match the names in actions_chosen\n",
    "for name in actions_chosen['name']:\n",
    "    for obj in actions_list:\n",
    "        if obj['action_name'] == name:\n",
    "            action_description = obj[\"action_description\"]\n",
    "            action_input = obj[\"input\"]\n",
    "            action_output = obj[\"output\"]\n",
    "            response = generate_prompt_from_action_prompt_chain.invoke({\n",
    "                \"action_description\": action_description,\n",
    "                \"action_input\": action_input,\n",
    "                \"action_output\": action_output,\n",
    "                \"query\": query,\n",
    "            })\n",
    "            selected_actions_prompts.append(response)\n",
    "\n",
    "print(selected_actions_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Chains\n",
    "############################################################# Graph State #############################################################\n",
    "class DBAgentGraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        query: query\n",
    "        database: database to route query\n",
    "        verbose: print debug statements?\n",
    "        output: LLM generation\n",
    "    \"\"\"\n",
    "    query : str\n",
    "    database : str\n",
    "    output: str\n",
    "    verbose : bool\n",
    "\n",
    "class DBAgent():\n",
    "    def __init__(self, llm, database_list: List[dict]):\n",
    "        self.database_list = database_list\n",
    "        self.llm = llm\n",
    "        self.chains = Chains(self.llm)\n",
    "        self.multi_db_router_chain = self.chains.get_multi_db_router_chain(self.database_list)\n",
    "        self.csvAgent = CSVAgentGPTInstance()\n",
    "\n",
    "    # Node - db_router\n",
    "    def db_router_node(self, state: DBAgentGraphState):\n",
    "        \"\"\"\n",
    "        dynamic routing to database listed in database_list\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            str: Next node to call\n",
    "        \"\"\"\n",
    "        if state['verbose']: print(\"Step: Routing Query\")\n",
    "        query = state['query']\n",
    "        output = self.multi_db_router_chain.invoke({\"query\": query})\n",
    "        if output['choice'] == \"NA\":\n",
    "            if state['verbose']: print(\"Step: Routing Query to General\")\n",
    "            return {'database': \"NA\"}\n",
    "        else:\n",
    "            if state['verbose']: print(\"Step: Routing Query to Database\")\n",
    "            return {'database': output['choice']}\n",
    "    \n",
    "    def db_router_edge(self, state: DBAgentGraphState):\n",
    "        \"\"\"\n",
    "        dynamic routing to database listed in database_list\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            str: Next node to call\n",
    "        \"\"\"\n",
    "        if state['database'] == \"NA\":\n",
    "            return \"general\"\n",
    "        else:\n",
    "            return \"db_query\"\n",
    "\n",
    "    def database_query(self, state: DBAgentGraphState):\n",
    "        \"\"\"\n",
    "        Generate answer\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, generation, that contains LLM generation\n",
    "        \"\"\"\n",
    "        \n",
    "        if state['verbose']: print(\"Step: Generating DB Response\")\n",
    "        query = state[\"query\"]\n",
    "        db_paths = []\n",
    "        for datab in state['database']:\n",
    "            selected_db = list(filter(lambda db: db.get('database_name') == datab, self.database_list))[0]\n",
    "            path_to_db = selected_db.get('database_path')\n",
    "            db_paths.append(path_to_db)\n",
    "        \n",
    "            \n",
    "        if len(db_paths) == 1:\n",
    "            response = self.csvAgent.get_csv_agent_output(db_paths[0], query)\n",
    "        else:\n",
    "            response = self.csvAgent.get_csv_agent_output(db_paths, query)\n",
    "            \n",
    "\n",
    "        return {\"output\": response}\n",
    "\n",
    "    def general(self, state: DBAgentGraphState):\n",
    "        \"\"\"\n",
    "        Generate answer\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, generation, that contains LLM generation\n",
    "        \"\"\"\n",
    "        \n",
    "        if state['verbose']: print(\"Step: Generating General Response\")\n",
    "        question = state[\"query\"]\n",
    "\n",
    "        # Answer Generation\n",
    "        print(f\"Answering general question: {question}\")\n",
    "        return None\n",
    "\n",
    "    def build_workflow(self):\n",
    "        \"\"\"\n",
    "        Build the workflow for the graph\n",
    "        \"\"\"\n",
    "        # Build the nodes\n",
    "        workflow = StateGraph(DBAgentGraphState)\n",
    "        workflow.add_node(\"db_router_node\", self.db_router_node)\n",
    "        workflow.add_node(\"general\", self.general)\n",
    "        workflow.add_node(\"db_query\", self.database_query)\n",
    "\n",
    "        # Set the entry point\n",
    "        workflow.set_entry_point(\"db_router_node\")\n",
    "\n",
    "        # Build the edges\n",
    "        workflow.add_conditional_edges(\n",
    "            \"db_router_node\",\n",
    "            self.db_router_edge,\n",
    "            {\n",
    "                \"general\": \"general\",\n",
    "                \"db_query\": \"db_query\",\n",
    "            },\n",
    "        )\n",
    "        workflow.add_edge(\"general\", END)\n",
    "        workflow.add_edge(\"db_query\", END)\n",
    "\n",
    "        # Compile the workflow\n",
    "        \n",
    "        local_agent = workflow.compile()\n",
    "\n",
    "        return local_agent\n",
    "\n",
    "    def run_agent(self, query, verbose=True):\n",
    "        local_agent = self.build_workflow()\n",
    "        output = local_agent.invoke({\"query\": query, \"verbose\": verbose})\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to write data to connection IPv4Address(('35d9c34f.databases.neo4j.io', 7687)) (ResolvedIPv4Address(('34.126.114.186', 7687)))\n",
      "Failed to write data to connection ResolvedIPv4Address(('34.126.114.186', 7687)) (ResolvedIPv4Address(('34.126.114.186', 7687)))\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n",
      "Step: Routing Query to Database\n",
      "Step: Generating DB Response\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[df['Address']=='13 Orchard Road']['Shop Name'].values[0]\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSingapore Outlet 9\u001b[0m\u001b[32;1m\u001b[1;3mThe supermarket name of the store located on 13 Orchard Road is \"Singapore Outlet 9\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what is the supermarket name of the store located on 13 orchard road',\n",
       " 'database': ['Outlet_database'],\n",
       " 'output': {'input': 'what is the supermarket name of the store located on 13 orchard road',\n",
       "  'output': 'The supermarket name of the store located on 13 Orchard Road is \"Singapore Outlet 9\".'},\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is the supermarket name of the store located on 13 orchard road\"\n",
    "DBAgent = DBAgent(llm, database_list)\n",
    "DBAgent.run_agent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Chains\n",
    "############################################################# Graph State #############################################################\n",
    "class ActionAgentGraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        query: query\n",
    "        database: database to route query\n",
    "        verbose: print debug statements?\n",
    "        output: LLM generation\n",
    "        action_prompts: action prompts\n",
    "        query_output: query output\n",
    "    \"\"\"\n",
    "    query: str\n",
    "    actions: str\n",
    "    actions_prompts: List[str]\n",
    "    query_output: List[str]\n",
    "    output: str\n",
    "    verbose: bool\n",
    "\n",
    "class ActionAgent():\n",
    "    def __init__(self, llm, actions_list: List[dict], database_list: List[dict]):\n",
    "        self.actions_list = actions_list\n",
    "        self.database_list = database_list\n",
    "        self.llm = llm\n",
    "        self.chains = Chains(self.llm)\n",
    "        self.action_router_chain = self.chains.get_action_router_chain(self.actions_list)\n",
    "        self.generate_action_prompt_chain = self.chains.get_generate_action_prompt_chain()\n",
    "        self.api_extract_input_chain = self.chains.get_api_extract_input_chain()\n",
    "        self.DBAgent = DBAgent(self.llm, self.database_list)\n",
    "\n",
    "    def actions_router_node(self, state: ActionAgentGraphState):\n",
    "        \"\"\"\n",
    "        dynamic choose which actions to take\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            str: Next node to call\n",
    "        \"\"\"\n",
    "        if state['verbose']: print(\"Step: Choosing Actions\")\n",
    "        query = state['query']\n",
    "        output = self.action_router_chain.invoke({\"query\": query})\n",
    "        if output['name'] == \"NA\":\n",
    "            if state['verbose']: print(\"Step: No Actions to Take\")\n",
    "            return {'actions': \"NA\"}\n",
    "        else:\n",
    "            selected_actions = [action for action in self.actions_list if action['action_name'] in output['name']]\n",
    "            api_type_actions = [action for action in selected_actions if action['action_type'] == 'api_call']\n",
    "            if len(api_type_actions) > 0:\n",
    "                if state['verbose']: print(\"Step: Routing Query to API Call Type Actions Stage\")\n",
    "                api_type_actions_names = [action['action_name'] for action in api_type_actions]\n",
    "                return {'actions': api_type_actions_names}\n",
    "            else:\n",
    "                if state['verbose']: print(\"Step: Routing Query to DB type Actions Prompting Stage\")\n",
    "                return {'actions': output['name']}\n",
    "    \n",
    "    def actions_router_edge(self, state: ActionAgentGraphState):\n",
    "        \"\"\"\n",
    "        dynamic routing to database listed in database_list\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            str: Next node to call\n",
    "        \"\"\"\n",
    "        if state['actions'] == \"NA\":\n",
    "            return \"general\"\n",
    "        else:\n",
    "            selected_actions = [action for action in self.actions_list if action['action_name'] in state['actions']]\n",
    "            api_type_actions = [action for action in selected_actions if action['action_type'] == 'api_call']\n",
    "            if len(api_type_actions) > 0:\n",
    "                return \"api_type_node\"\n",
    "            else:\n",
    "                return \"generate_action_prompt\"\n",
    "    \n",
    "    def api_type_node(self, state: ActionAgentGraphState):\n",
    "        \"\"\"\n",
    "        Generate answer\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, generation, that contains LLM generation\n",
    "        \"\"\"\n",
    "        \n",
    "        if state['verbose']: print(\"Step: Generating API Call Response\")\n",
    "        selected_actions = [action for action in self.actions_list if action['action_name'] in state['actions']]\n",
    "        response = self.api_extract_input_chain.invoke({\n",
    "            \"query\": state[\"query\"],\n",
    "            \"action_name\": selected_actions[0]['action_name'],\n",
    "            \"action_desc\": selected_actions[0]['action_description'],\n",
    "            \"action_input\": str(selected_actions[0]['input'])\n",
    "        })\n",
    "        payload = {\n",
    "            \"action_name\": selected_actions[0]['action_name'],\n",
    "            \"action_desc\": selected_actions[0]['action_description'],\n",
    "            'extracted_inputs': response\n",
    "        }\n",
    "        return {\"output\": payload}\n",
    "    \n",
    "    def generate_action_prompt(self, state: ActionAgentGraphState):\n",
    "        \"\"\"\n",
    "        Generate answer\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, generation, that contains LLM generation\n",
    "        \"\"\"\n",
    "        \n",
    "        if state['verbose']: print(\"Step: Generating Action Prompt\")\n",
    "        print(\"Actions: \" + str(state['actions']))\n",
    "        action_prompts = []\n",
    "        for action in state['actions']:\n",
    "            selected_action = list(filter(lambda act: act.get('action_name') == action, self.actions_list))[0]\n",
    "            \n",
    "            response = self.generate_action_prompt_chain.invoke({\n",
    "                \"action_description\": selected_action[\"action_description\"],\n",
    "                \"action_input\": selected_action[\"input\"],\n",
    "                \"action_output\": selected_action[\"output\"],\n",
    "                \"query\": state[\"query\"],\n",
    "            })\n",
    "            action_prompts.append(response)\n",
    "\n",
    "        return {\"actions_prompts\": action_prompts}\n",
    "    \n",
    "    def db_query(self, state: ActionAgentGraphState):\n",
    "        \"\"\"\n",
    "        Generate answer\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, generation, that contains LLM generation\n",
    "        \"\"\"\n",
    "        \n",
    "        if state['verbose']: print(\"Step: Generating DB Response\")\n",
    "        query_output = []\n",
    "        for action_prompt in state['actions_prompts']:\n",
    "            response = self.DBAgent.run_agent(action_prompt)\n",
    "            query_output.append(response)\n",
    "\n",
    "        return {\"query_output\": query_output}\n",
    "    \n",
    "    def generate_final_output(self, state: ActionAgentGraphState):\n",
    "        \"\"\"\n",
    "        Generate answer\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, generation, that contains LLM generation\n",
    "        \"\"\"\n",
    "        \n",
    "        if state['verbose']: print(\"Step: Generating Final Response\")\n",
    "        query_output = state[\"query_output\"]\n",
    "        output_strings = [item['output']['output'] for item in query_output]\n",
    "        final_output_chain = self.chains.get_final_output_chain(output_strings)\n",
    "        response = final_output_chain.invoke({\"query\": state[\"query\"]})\n",
    "        return {\"output\": response}\n",
    "    \n",
    "    def general(self, state: ActionAgentGraphState):\n",
    "        \"\"\"\n",
    "        Generate answer\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, generation, that contains LLM generation\n",
    "        \"\"\"\n",
    "        \n",
    "        if state['verbose']: print(\"Step: Generating General Response\")\n",
    "        question = state[\"query\"]\n",
    "\n",
    "        # Answer Generation\n",
    "        print(f\"Answering general question: {question}\")\n",
    "        return None\n",
    "\n",
    "    def build_workflow(self):\n",
    "        \"\"\"\n",
    "        Build the workflow for the graph\n",
    "        \"\"\"\n",
    "        # Build the nodes\n",
    "        workflow = StateGraph(ActionAgentGraphState)\n",
    "        workflow.add_node(\"actions_router_node\", self.actions_router_node)\n",
    "        workflow.add_node(\"general\", self.general)\n",
    "        workflow.add_node(\"generate_action_prompt\", self.generate_action_prompt)\n",
    "        workflow.add_node(\"db_query\", self.db_query)\n",
    "        workflow.add_node(\"generate_final_output\", self.generate_final_output)\n",
    "        workflow.add_node(\"api_type_node\", self.api_type_node)\n",
    "\n",
    "        # Set the entry point\n",
    "        workflow.set_entry_point(\"actions_router_node\")\n",
    "\n",
    "        # Build the edges\n",
    "        workflow.add_conditional_edges(\n",
    "            \"actions_router_node\",\n",
    "            self.actions_router_edge,\n",
    "            {\n",
    "                \"general\": \"general\",\n",
    "                \"generate_action_prompt\": \"generate_action_prompt\",\n",
    "                \"api_type_node\": \"api_type_node\",\n",
    "            },\n",
    "        )\n",
    "        workflow.add_edge(\"general\", END)\n",
    "        workflow.add_edge(\"generate_action_prompt\", \"db_query\")\n",
    "        workflow.add_edge(\"db_query\", \"generate_final_output\")\n",
    "        workflow.add_edge(\"generate_final_output\", END)\n",
    "        workflow.add_edge(\"api_type_node\", END)\n",
    "\n",
    "        # Compile the workflow\n",
    "        \n",
    "        local_agent = workflow.compile()\n",
    "\n",
    "        return local_agent\n",
    "\n",
    "    def run_agent(self, query, verbose=True):\n",
    "        local_agent = self.build_workflow()\n",
    "        output = local_agent.invoke({\"query\": query, \"verbose\": verbose})\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    }
   ],
   "source": [
    "ActionAgent = ActionAgent(llm, actions_list, database_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Choosing Actions\n",
      "Step: Routing Query to DB type Actions Prompting Stage\n",
      "Step: Generating Action Prompt\n",
      "Actions: ['most_product_sales_for_shop', 'most_customer_sales_for_shop']\n",
      "Step: Generating DB Response\n",
      "Step: Routing Query\n",
      "Step: Routing Query to Database\n",
      "Step: Generating DB Response\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df = df1.merge(df2, on='Product ID')\\nmost_sold_product = df[df['Shop ID'] == 'SG1'].groupby('Product Name')['Quantity'].sum().idxmax()\\nmost_sold_product\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mEau de Toilette\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[df['Product Name'] == 'Eau de Toilette']['Product ID'].iloc[0]\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mES41\u001b[0m\u001b[32;1m\u001b[1;3mThe product name that had the most sales from Singapore Outlet 1 is \"Eau de Toilette\". The product ID for this product is ES41.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Step: Routing Query\n",
      "Step: Routing Query to Database\n",
      "Step: Generating DB Response\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df = df1.merge(df2, on='Shop ID')\\nmax_sales_customer = df[(df['Shop Name'] == 'Singapore Outlet 1')].groupby('Customer ID')['Total Price'].sum().idxmax()\\ncustomer_name = df3[df3['Customer ID'] == max_sales_customer]['Customer Name'].values[0]\\ncustomer_name\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m John Doe\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df3[df3['Customer Name'] == 'John Doe']['Customer ID'].values[0]\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mIndexError: index 0 is out of bounds for axis 0 with size 0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df = df1.merge(df2, on='Shop ID')\\nmax_sales_customer = df[(df['Shop Name'] == 'Singapore Outlet 1')].groupby('Customer ID')['Total Price'].sum().idxmax()\\ncustomer_id = df3[df3['Customer Name'] == 'John Doe']['Customer ID'].values[0]\\ncustomer_id\"}`\n",
      "responded: It seems there was an issue with finding the customer ID for the customer with the most sales from Singapore Outlet 1. Let me correct that and provide you with the correct customer ID.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mIndexError: index 0 is out of bounds for axis 0 with size 0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df = df1.merge(df2, on='Shop ID')\\nmax_sales_customer = df[(df['Shop Name'] == 'Singapore Outlet 1')].groupby('Customer ID')['Total Price'].sum().idxmax()\\ncustomer_id = max_sales_customer\\ncustomer_id\"}`\n",
      "responded: It seems there was an issue with retrieving the customer ID for the customer with the most sales from Singapore Outlet 1. Let me try a different approach to find the correct customer ID.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m7\u001b[0m\u001b[32;1m\u001b[1;3mThe customer with the most sales from Singapore Outlet 1 is John Doe, and the customer ID for John Doe is 7.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Step: Generating Final Response\n"
     ]
    }
   ],
   "source": [
    "query = \"Summarize the sales for Singapore Outlet 1.\"\n",
    "\n",
    "output = ActionAgent.run_agent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action_name': 'create_jira_issue',\n",
       " 'action_desc': 'Creates a Jira Issue with the given details.',\n",
       " 'extracted_inputs': {'issue title': 'Bug in the system',\n",
       "  'issue description': 'The system is not responding',\n",
       "  'issue type': '',\n",
       "  'issue priority': ''}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Choosing Actions\n",
      "Step: Routing Query to API Call Type Actions Stage\n",
      "Step: Generating API Call Response\n"
     ]
    }
   ],
   "source": [
    "query = \"Help me create a Jira Issue with the title 'Bug in the system' and description 'The system is not responding'.\"\n",
    "\n",
    "output = ActionAgent.run_agent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Choosing Actions\n",
      "Step: No Actions to Take\n",
      "Step: Generating General Response\n",
      "Answering general question: Hi, how are you?\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "query = \"Hi, how are you?\"\n",
    "\n",
    "output = ActionAgent.run_agent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
