{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Displaying final output format\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "# Langchain Dependencies\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langgraph.graph import END, StateGraph\n",
    "# For State Graph \n",
    "from typing_extensions import TypedDict\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.runnables import (\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Tuple, List, Optional\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "from langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\n",
    "\n",
    "from utils import CSVAgentGPTInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "llm_json = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, model_kwargs={\"response_format\": {\"type\": \"json_object\"}})\n",
    "\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'general'}\n"
     ]
    }
   ],
   "source": [
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(),\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, object, location, or event entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting person, object, location, or event entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "entity_chain = prompt | llm.with_structured_output(Entities)\n",
    "\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a full-text search query for a given input string.\n",
    "\n",
    "    This function constructs a query string suitable for a full-text search.\n",
    "    It processes the input string by splitting it into words and appending a\n",
    "    similarity threshold (~2 changed characters) to each word, then combines\n",
    "    them using the AND operator. Useful for mapping entities from user questions\n",
    "    to database values, and allows for some misspelings.\n",
    "    \"\"\"\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()\n",
    "\n",
    "# Fulltext index query\n",
    "def structured_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"\n",
    "            CALL db.index.fulltext.queryNodes('entity', $query, {limit: 2})\n",
    "            YIELD node, score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' + node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result\n",
    "\n",
    "def retriever(question: str):\n",
    "    structured_data = structured_retriever(question)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
    "    final_data = f\"\"\"Structured data:\n",
    "        {structured_data}\n",
    "        Unstructured data:\n",
    "        {\"#Document \". join(unstructured_data)}\n",
    "    \"\"\"\n",
    "    return final_data\n",
    "\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n",
    "in its original language.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"  # noqa: E501\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer\n",
    "\n",
    "_search_query = RunnableBranch(\n",
    "    # If input includes chat_history, we condense it with the follow-up question\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "            run_name=\"HasChatHistoryCheck\"\n",
    "        ),  # Condense follow-up question and chat into a standalone_question\n",
    "        RunnablePassthrough.assign(\n",
    "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        )\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | ChatOpenAI(temperature=0)\n",
    "        | StrOutputParser(),\n",
    "    ),\n",
    "    # Else, we have no chat history, so just pass through the question\n",
    "    RunnableLambda(lambda x : x[\"question\"]),\n",
    ")\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Use natural language and be as elaborate as possible.\n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": _search_query | retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def invoke_chain(question: str, chat_history):\n",
    "    graph.query(\n",
    "        \"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n",
    "    if chat_history:\n",
    "        return chain.invoke(\n",
    "            {\n",
    "                \"question\": question,\n",
    "                \"chat_history\": chat_history\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return chain.invoke(\n",
    "            {\n",
    "                \"question\": question,\n",
    "            }\n",
    "        )\n",
    "    \n",
    "\n",
    "# Router\n",
    "router_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an expert at routing a user question to either the generation stage or general query stage. \n",
    "    Use the general query for questions that does not require additional contextual information.\n",
    "    Otherwise, you can skip and go straight to the generation phase to respond.\n",
    "    You do not need to be stringent with the keywords in the question related to these topics.\n",
    "    Give a binary choice 'general' or 'generate' based on the question. \n",
    "    Return the JSON with a single key 'choice' with no premable or explanation. \n",
    "    \n",
    "    Question to route: {question} \n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "question_router = router_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# Test Run\n",
    "question = \"What's up?\"\n",
    "print(question_router.invoke({\"question\": question}))\n",
    "\n",
    "# General chain\n",
    "general_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an expert at answering general questions. \n",
    "    Use the general query for questions that does not require additional contextual information.\n",
    "    You do not need to be stringent with the keywords in the question related to these topics.\n",
    "    Answer the following question in a natural language. \n",
    "    \n",
    "    Question: {question} \n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "general_chain = general_prompt | llm | StrOutputParser()\n",
    "\n",
    "  \n",
    "############################################################# Graph State #############################################################\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        search_query: revised question for web search\n",
    "        context: web_search result\n",
    "    \"\"\"\n",
    "    question : str\n",
    "    generation : str\n",
    "    search_query : str\n",
    "    context : str\n",
    "\n",
    "# Node - Generate\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Step: Generating Final Response\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Answer Generation\n",
    "    generation = invoke_chain(question, None)\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "def general(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Step: Generating Final Response\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Answer Generation\n",
    "    generation = general_chain.invoke({\"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "# Conditional Edge, Routing\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    route question to web search or generation.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Step: Routing Query\")\n",
    "    question = state['question']\n",
    "    output = question_router.invoke({\"question\": question})\n",
    "    if output['choice'] == \"general\":\n",
    "        print(\"Step: Routing Query to General\")\n",
    "        return \"general\"\n",
    "    elif output['choice'] == 'generate':\n",
    "        print(\"Step: Routing Query to Generation\")\n",
    "        return \"generate\"\n",
    "    \n",
    "def build_workflow():\n",
    "    \"\"\"\n",
    "    Build the workflow for the graph\n",
    "    \"\"\"\n",
    "    # Build the nodes\n",
    "    workflow = StateGraph(GraphState)\n",
    "    workflow.add_node(\"general\", general)\n",
    "    workflow.add_node(\"generate\", generate)\n",
    "\n",
    "    # Build the edges\n",
    "    workflow.set_conditional_entry_point(\n",
    "        route_question,\n",
    "        {\n",
    "            \"general\": \"general\",\n",
    "            \"generate\": \"generate\",\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"general\", END)\n",
    "    workflow.add_edge(\"generate\", END)\n",
    "\n",
    "    # Compile the workflow\n",
    "    local_agent = workflow.compile()\n",
    "\n",
    "    return local_agent\n",
    "\n",
    "def run_agent(query, local_agent):\n",
    "    output = local_agent.invoke({\"question\": query})\n",
    "    print(\"=======\")\n",
    "    display(Markdown(output[\"generation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n",
      "Step: Routing Query to Generation\n",
      "Step: Generating Final Response\n",
      "=======\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but without any specific information or data provided in the context, I am unable to answer the question about how many sales TikTok made yesterday. In order to provide an accurate answer, I would need more details or data related to TikTok's sales from yesterday."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test it out!\n",
    "agent = build_workflow()\n",
    "run_agent(\"How many sales did TikTok make yesterday?\", agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "llm_json = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, model_kwargs={\"response_format\": {\"type\": \"json_object\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "added actions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_list = [\n",
    "  {\n",
    "    \"database_name\": \"Sales_database123\",\n",
    "    \"database_description\": \"A database that contains information about supermarket sales.\",\n",
    "    'columns': \"Invoice ID, Product ID, Shop ID, Customer ID, Date, Time, Payment, Unit Price, Quantity, Total Price\",\n",
    "    \"database_path\": \"../csv_db/supermarket_sales_db.csv\",\n",
    "  },\n",
    "  {\n",
    "    \"database_name\": \"Outlet_database\",\n",
    "    \"database_description\": \"A database that contains information about physical outlets.\",\n",
    "    \"columns\": \"Shop ID, Country, City, State, Shop Name, Shop Type, Shop Size, Address\",\n",
    "    \"database_path\": \"../csv_db/shop_outlet_db.csv\",\n",
    "  },\n",
    "  {\n",
    "    \"database_name\": \"Customer_database\",\n",
    "    \"database_description\": \"A database that contains information about customers.\",\n",
    "    \"columns\": \"Customer ID, Customer Name, Customer Email, Customer Phone, Customer Address, Gender, Age\",\n",
    "    \"database_path\": \"../csv_db/customer_db.csv\",\n",
    "  },\n",
    "  {\n",
    "    \"database_name\": \"Product_database\",\n",
    "    \"database_description\": \"A database that contains information about products.\",\n",
    "    \"columns\": \"Product ID, Product Name, Product Price, Product Category\",\n",
    "    \"database_path\": \"../csv_db/product_db.csv\",\n",
    "  },\n",
    "]\n",
    "\n",
    "actions_list = [\n",
    "  {\n",
    "    \"action_type\": \"query_database\",\n",
    "    \"action_name\": \"most_product_sales_for_shop\",\n",
    "    \"action_description\": \"Search for which product had the most sales from a specific shop.\",\n",
    "    \"input\": [\"sales\", \"shop name\",],\n",
    "    \"output\": [\"product name\", \"product ID\",],\n",
    "  },\n",
    "  {\n",
    "    \"action_type\": \"query_database\",\n",
    "    \"action_name\": \"most_customer_sales_for_shop\",\n",
    "    \"action_description\": \"Search for which customer had the most sales from a specific shop.\",\n",
    "    \"input\": [\"sales\", \"shop name\",],\n",
    "    \"output\": [\"customer name\", \"customer ID\",],\n",
    "  },\n",
    "  {\n",
    "    \"action_type\": \"query_database\",\n",
    "    \"action_name\": \"full_description_of_product\",\n",
    "    \"action_description\": \"Give the full description of a product.\",\n",
    "    \"input\": [\"product name\",],\n",
    "    \"output\": [\"product ID\", \"product name\", \"product price\", \"product category\",],\n",
    "  },\n",
    "  {\n",
    "    \"action_type\": \"api_call\",\n",
    "    \"action_name\": \"create_jira_issue\",\n",
    "    \"action_description\": \"Creates a Jira Issue with the given details.\",\n",
    "    \"input\": [\"issue title\", \"issue description\", \"issue type\", \"issue priority\",],\n",
    "    \"output\": [],\n",
    "  },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "added chain to identify which action to select\n",
    "\n",
    "few shot dont work for actions for some reason ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### DB Routing ######################\n",
    "\n",
    "example_db_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "      (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        Database name: {database_name}\n",
    "        Database description: {database_description}\n",
    "        Database columns: {columns}\n",
    "        \"\"\",\n",
    "      ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "db_few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "  example_prompt=example_db_prompt,\n",
    "  examples=database_list,\n",
    ")\n",
    "\n",
    "db_router_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      You are a expert at routing a user query to one of the database provided below. \n",
    "      Your choice should be one of the database's name. \n",
    "      You can return NA if the query is not related to any of the databases.\n",
    "      Return the JSON with a single key 'choice' with no premable or explanation.\n",
    "\n",
    "      Choices:\n",
    "      \"\"\"\n",
    "    ),\n",
    "    db_few_shot_prompt,\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "      \"Query: {query}\"\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "multi_db_router_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      You are a expert at routing a user query to the database provided below. \n",
    "      You can select more than one database if the query requires information from multiple databases.\n",
    "      Your choices should be the database's name. \n",
    "      You can return NA if the query is not related to any of the databases.\n",
    "      You should return a list of database names.\n",
    "      Return the JSON with a single key 'choice' with no premable or explanation.\n",
    "\n",
    "      Choices:\n",
    "      \"\"\"\n",
    "    ),\n",
    "    db_few_shot_prompt,\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "      \"Query: {query}\"\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "###################### Choose Which Action ######################\n",
    "\n",
    "choose_action_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      You are an intelligent assistant. \n",
    "      Your task is to match a user's query to a list of actions based on the inputs required for each action. \n",
    "      Each action has a specific set of inputs that it requires. \n",
    "      You should identify which actions can be taken based on the inputs mentioned in the user's query and return those actions in JSON format.\n",
    "      Return NA if and only if the query is not related to any of the actions.\n",
    "      You should return a list of database names.\n",
    "      Return the JSON with a single key 'name' with no premable or explanation.\n",
    "\n",
    "      Choices:\n",
    "      \"\"\"\n",
    "    ),\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "            \"\\n\".join(\n",
    "                [\n",
    "                    f\"\"\"\n",
    "                    Action type: {action['action_type']}\n",
    "                    Action name: {action['action_name']}\n",
    "                    Action description: {action['action_description']}\n",
    "                    Action input: {action['input']}\n",
    "                    Action output: {action['output']}\n",
    "                    \"\"\"\n",
    "                    for action in actions_list\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "      \"Query: {query}\"\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "###################### Generate Prompt from Action Prompt ######################\n",
    "\n",
    "# Few Shot Chat Message Prompt Template\n",
    "generate_prompt_from_action_prompt_examples = [\n",
    "  {\n",
    "    \"query\": \"Summarize the sales for Shop A.\",\n",
    "    \"action_description\": \"Search for which product had the most sales from a specific shop.\",\n",
    "    \"action_input\": [\"sales\", \"shop name\"],\n",
    "    \"action_output\": [\"product name\", \"product ID\"],\n",
    "    \"answer\": \"First, give me the name of the product that had the most sales from Shop A. Then, use that product name to find the product ID.\"\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Summarize the sales for Shop A.\",\n",
    "    \"action_description\": \"Search for which customer had the most sales from a specific shop.\",\n",
    "    \"action_input\": [\"sales\", \"shop name\"],\n",
    "    \"action_output\": [\"customer name\", \"customer ID\"],\n",
    "    \"answer\": \"First, give me the name of the customer that bought the most items from Shop A. Then, use that customer name to find the customer ID.\"\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Summarize the sales for Country A.\",\n",
    "    \"action_description\": \"Search for the city which had the highest quantity of items sold in a specific country.\",\n",
    "    \"action_input\": [\"sales\", \"country name\"],\n",
    "    \"action_output\": [\"city name\", \"quantity\"],\n",
    "    \"answer\": \"First, give me the city name which had the highest quantity of items sold in Country A. Then, give me the total quantity of items sold for that city.\"\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Give report on Customer A.\",\n",
    "    \"action_description\": \"Give the full details of a customer.\",\n",
    "    \"action_input\": [\"customer name\"],\n",
    "    \"action_output\": [\"customer ID\", \"customer name\", \"customer email\", \"customer phone\", \"customer address\", \"gender\", \"age\"],\n",
    "    \"answer\": \"Give me the customer ID, customer name, customer email, customer phone, customer address, gender, age of customer A.\"\n",
    "  }\n",
    "]\n",
    "\n",
    "generate_prompt_from_action_prompt_example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "      (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        Query: {query}\n",
    "        Action description: {action_description}\n",
    "        Action input: {action_input}\n",
    "        Action output: {action_output}\n",
    "        Answer: {answer}\n",
    "        \"\"\",\n",
    "      ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "generate_prompt_from_action_prompt_fewshotprompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=generate_prompt_from_action_prompt_examples,\n",
    "    example_prompt=generate_prompt_from_action_prompt_example_prompt,\n",
    ")\n",
    "\n",
    "# Prompt to generate systematic and precise output\n",
    "generate_prompt_from_action_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"      \n",
    "      You are an intelligent assistant. Your task is to create systematic and precise prompts to be fed to another llm,\n",
    "      based on a user's query and a list of actions.\n",
    "      Each action has a specific set of inputs and outputs. You should first identify the main action from the query.\n",
    "      Then, generate instructions that use intermediate results precisely.\n",
    "      Generate the step-by-step instructions using the action's inputs and outputs,\n",
    "      ensuring intermediate results are clearly stated and used in subsequent steps.\n",
    "      \"\"\"\n",
    "    ),\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      For the action:\n",
    "      Action description: {action_description}\n",
    "      Action input: {action_input}\n",
    "      Action output: {action_output}\n",
    "\n",
    "      Based on the query: \"{query}\", generate the output based on the action and the query.\n",
    "      \n",
    "      I will provide some examples to help you understand the task.\n",
    "      \n",
    "      Examples:\n",
    "\n",
    "      \"\"\"\n",
    "    ),\n",
    "    generate_prompt_from_action_prompt_fewshotprompt,\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      Do not include any explanation or preamble. Only return the actual answer.\n",
    "      \n",
    "      Return the answer as a string in natural language, in prose, with no bullet points, point form, or list format.\n",
    "      \"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "      \"Query: {query}\",\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "###################### Generate Final Output From Actions and Query ######################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_router_chain = db_router_prompt | llm | JsonOutputParser()\n",
    "multi_db_router_chain = multi_db_router_prompt | llm | JsonOutputParser()\n",
    "action_router_chain = choose_action_prompt | llm | JsonOutputParser()\n",
    "generate_prompt_from_action_prompt_chain = generate_prompt_from_action_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choice': ['Product_database']}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_db_router_chain.invoke({\"query\": \"What is the product id and product category of Eau de Toilette?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test action router chain. Preliminary testing seems good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['most_product_sales_for_shop', 'most_customer_sales_for_shop']}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_router_chain.invoke({\"query\": \"Summarize the sales for Singapore Outlet 1.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['create_jira_issue']}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_router_chain.invoke({\"query\": \"Create a Jira Issue with the title 'Bug in the system' and description 'The system is not responding'.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one below seems inconsistent between NA and most_product_sales_for_shop??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['most_product_sales_for_shop']}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_router_chain.invoke({\"query\": \"give me the city name with the highest quantity of items sold for Kuala Lumpur\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test generate action prompt. Seems good for the example_action_list given above also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_type': 'query_database', 'action_name': 'full_description_of_product', 'action_description': 'Give the full description of a product.', 'input': ['product name'], 'output': ['product ID', 'product name', 'product price', 'product category']}\n",
      "Give me the product ID, product name, product price, and product category of the product named Eau de Toilette.\n"
     ]
    }
   ],
   "source": [
    "test_action_1 = actions_list[2]\n",
    "print(test_action_1)\n",
    "\n",
    "response = generate_prompt_from_action_prompt_chain.invoke({\n",
    "    \"action_description\": test_action_1[\"action_description\"],\n",
    "    \"action_input\": test_action_1[\"input\"],\n",
    "    \"action_output\": test_action_1[\"output\"],\n",
    "    \"query\": \"Summarize product Eau de Toilette\",\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': ['most_product_sales_for_shop', 'most_customer_sales_for_shop']}\n",
      "['First, give me the name of the product that had the most sales from Singapore Outlet 1. Then, use that product name to find the product ID.', 'First, give me the name of the customer that had the most sales from Singapore Outlet 1. Then, use that customer name to find the customer ID.']\n"
     ]
    }
   ],
   "source": [
    "actions_chosen = action_router_chain.invoke({\"query\": \"Summarize the sales for Singapore Outlet 1.\"})\n",
    "print(actions_chosen)\n",
    "\n",
    "selected_actions_prompts = []\n",
    "query = \"Summarize the sales for Singapore Outlet 1.\"\n",
    "\n",
    "# Retrieve objects that match the names in actions_chosen\n",
    "for name in actions_chosen['name']:\n",
    "    for obj in actions_list:\n",
    "        if obj['action_name'] == name:\n",
    "            action_description = obj[\"action_description\"]\n",
    "            action_input = obj[\"input\"]\n",
    "            action_output = obj[\"output\"]\n",
    "            response = generate_prompt_from_action_prompt_chain.invoke({\n",
    "                \"action_description\": action_description,\n",
    "                \"action_input\": action_input,\n",
    "                \"action_output\": action_output,\n",
    "                \"query\": query,\n",
    "            })\n",
    "            selected_actions_prompts.append(response)\n",
    "\n",
    "print(selected_actions_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################# Graph State #############################################################\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        query: query\n",
    "        database: database to route query\n",
    "        verbose: print debug statements?\n",
    "        output: LLM generation\n",
    "    \"\"\"\n",
    "    query : str\n",
    "    database : str\n",
    "    output: str\n",
    "    verbose : bool\n",
    "\n",
    "# Node - db_router\n",
    "def db_router_node(state: GraphState):\n",
    "    \"\"\"\n",
    "    dynamic routing to database listed in database_list\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    if state['verbose']: print(\"Step: Routing Query\")\n",
    "    query = state['query']\n",
    "    output = multi_db_router_chain.invoke({\"query\": query})\n",
    "    if output['choice'] == \"NA\":\n",
    "        if state['verbose']: print(\"Step: Routing Query to General\")\n",
    "        return {'database': \"NA\"}\n",
    "    else:\n",
    "        if state['verbose']: print(\"Step: Routing Query to Database\")\n",
    "        return {'database': output['choice']}\n",
    "    \n",
    "def db_router_edge(state: GraphState):\n",
    "    \"\"\"\n",
    "    dynamic routing to database listed in database_list\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    if state['database'] == \"NA\":\n",
    "        return \"general\"\n",
    "    else:\n",
    "        return \"db_query\"\n",
    "\n",
    "def database_query(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    if state['verbose']: print(\"Step: Generating DB Response\")\n",
    "    query = state[\"query\"]\n",
    "    db_paths = []\n",
    "    for datab in state['database']:\n",
    "        selected_db = list(filter(lambda db: db.get('database_name') == datab, database_list))[0]\n",
    "        path_to_db = selected_db.get('database_path')\n",
    "        db_paths.append(path_to_db)\n",
    "    csvAgent = CSVAgentGPTInstance()\n",
    "        \n",
    "    if len(db_paths) == 1:\n",
    "        response = csvAgent.get_csv_agent_output(db_paths[0], query)\n",
    "    else:\n",
    "        response = csvAgent.get_csv_agent_output(db_paths, query)\n",
    "        \n",
    "    # selected_db = list(filter(lambda db: db.get('database_name') == state['database'], database_list))[0]\n",
    "    # path_to_db = selected_db.get('database_path')\n",
    "    # csvAgent = CSVAgentGPTInstance()\n",
    "    # response = csvAgent.get_csv_agent_output(path_to_db, query)\n",
    "\n",
    "    return None\n",
    "\n",
    "def general(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    if state['verbose']: print(\"Step: Generating General Response\")\n",
    "    question = state[\"query\"]\n",
    "\n",
    "    # Answer Generation\n",
    "    print(f\"Answering general question: {question}\")\n",
    "    return None\n",
    "\n",
    "def build_workflow():\n",
    "    \"\"\"\n",
    "    Build the workflow for the graph\n",
    "    \"\"\"\n",
    "    # Build the nodes\n",
    "    workflow = StateGraph(GraphState)\n",
    "    workflow.add_node(\"db_router_node\", db_router_node)\n",
    "    workflow.add_node(\"general\", general)\n",
    "    workflow.add_node(\"db_query\", database_query)\n",
    "\n",
    "    # Set the entry point\n",
    "    workflow.set_entry_point(\"db_router_node\")\n",
    "\n",
    "    # Build the edges\n",
    "    workflow.add_conditional_edges(\n",
    "        \"db_router_node\",\n",
    "        db_router_edge,\n",
    "        {\n",
    "            \"general\": \"general\",\n",
    "            \"db_query\": \"db_query\",\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"general\", END)\n",
    "    workflow.add_edge(\"db_query\", END)\n",
    "\n",
    "    # Compile the workflow\n",
    "    \n",
    "    local_agent = workflow.compile()\n",
    "\n",
    "    return local_agent\n",
    "\n",
    "def run_agent(query, local_agent, verbose=True):\n",
    "    output = local_agent.invoke({\"query\": query, \"verbose\": verbose})\n",
    "    print(\"=======\")\n",
    "    if output.get('output'):\n",
    "        display(Markdown(output[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = build_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n",
      "Step: Routing Query to Database\n",
      "Step: Generating DB Response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[df['Product Name'] == 'Eau de Toilette'][['Product ID', 'Product Name', 'Product Price', 'Product Category']]\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m  Product ID     Product Name  Product Price Product Category\n",
      "0       ES41  Eau de Toilette          74.69           Beauty\u001b[0m\u001b[32;1m\u001b[1;3mThe product ID, product name, product price, and product category for the product named Eau de Toilette are as follows:\n",
      "- Product ID: ES41\n",
      "- Product Name: Eau de Toilette\n",
      "- Product Price: $74.69\n",
      "- Product Category: Beauty\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "=======\n"
     ]
    }
   ],
   "source": [
    "query = \"First, provide me with the product ID, product name, product price, and product category for the product named Eau de Toilette.\"\n",
    "run_agent(query, agent, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n",
      "Step: Routing Query to Database\n",
      "Step: Generating DB Response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df1.merge(df2, on='Shop ID').groupby('City')['Quantity'].sum().loc[df2[df2['Country']=='Malaysia']['City'].iloc[0] if df2['Country'].str.contains('Malaysia').any() else ''].idxmax()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAttributeError: 'numpy.int64' object has no attribute 'idxmax'\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df1.merge(df2, on='Shop ID').groupby('City')['Quantity'].sum().loc[df2[df2['Country']=='Malaysia']['City'].iloc[0] if df2['Country'].str.contains('Malaysia').any() else ''].idxmax()\"}`\n",
      "responded: It seems there was an error in retrieving the city name with the highest quantity of items sold in Malaysia. Let me correct that and provide you with the correct city name.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAttributeError: 'numpy.int64' object has no attribute 'idxmax'\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df1.merge(df2, on='Shop ID').groupby('City')['Quantity'].sum().idxmax()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSingapore\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df1.merge(df2, on='Shop ID').groupby('City')['Quantity'].sum().max()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m57\u001b[0m\u001b[32;1m\u001b[1;3mThe city with the highest quantity of items sold in Malaysia is Singapore, with a total quantity of 57 items sold.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "=======\n"
     ]
    }
   ],
   "source": [
    "query = \"First, give me the city name which had the highest quantity of items sold in Malaysia. Then, give me the total quantity of items sold for that city.\"\n",
    "run_agent(query, agent, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"First, give me the city name which had the highest quantity of items sold in Malaysia. Then, give me the total quantity of items sold for that city.\"\n",
    "run_agent(query, agent, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n",
      "Step: Routing Query to Database\n",
      "Step: Generating DB Response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"total_quantity_penang = df1[df1['Shop ID'].str.startswith('MY')]['Quantity'].sum()\\ntotal_quantity_penang\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m75\u001b[0m\u001b[32;1m\u001b[1;3mThe total quantity of items sold for Penang is 75.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "=======\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me the total quantity of items sold for Penang.\"\n",
    "run_agent(query, agent, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n",
      "Step: Routing Query to Database\n",
      "Step: Generating DB Response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[df['Product Name'] == 'Eau de Toilette']['Product ID'].values[0]\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mES41\u001b[0m\u001b[32;1m\u001b[1;3mThe product ID of \"Eau de Toilette\" is ES41.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "=======\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the product id of Eau de Toilette?\"\n",
    "run_agent(query, agent, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################# Graph State #############################################################\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        query: query\n",
    "        database: database to route query\n",
    "        verbose: print debug statements?\n",
    "        output: LLM generation\n",
    "    \"\"\"\n",
    "    query : str\n",
    "    database : str\n",
    "    output: str\n",
    "    verbose : bool\n",
    "\n",
    "# Node - db_router\n",
    "def db_router_node(state: GraphState):\n",
    "    \"\"\"\n",
    "    dynamic routing to database listed in database_list\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    if state['verbose']: print(\"Step: Routing Query\")\n",
    "    query = state['query']\n",
    "    output = db_router_chain.invoke({\"query\": query})\n",
    "    if output['choice'] == \"NA\":\n",
    "        if state['verbose']: print(\"Step: Routing Query to General\")\n",
    "        return {'database': \"NA\"}\n",
    "    else:\n",
    "        if state['verbose']: print(\"Step: Routing Query to Database\")\n",
    "        return {'database': output['choice']}\n",
    "    \n",
    "def db_router_edge(state: GraphState):\n",
    "    \"\"\"\n",
    "    dynamic routing to database listed in database_list\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    if state['database'] == \"NA\":\n",
    "        return \"general\"\n",
    "    else:\n",
    "        return \"db_query\"\n",
    "\n",
    "def database_query(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    if state['verbose']: print(\"Step: Generating DB Response\")\n",
    "    query = state[\"query\"]\n",
    "    selected_db = list(filter(lambda db: db.get('database_name') == state['database'], database_list))[0]\n",
    "    path_to_db = selected_db.get('database_path')\n",
    "    csvAgent = CSVAgentGPTInstance()\n",
    "    response = csvAgent.get_csv_agent_output(path_to_db, query)\n",
    "\n",
    "    return {\"output\": response['output']}\n",
    "\n",
    "def general(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    if state['verbose']: print(\"Step: Generating General Response\")\n",
    "    question = state[\"query\"]\n",
    "\n",
    "    # Answer Generation\n",
    "    print(f\"Answering general question: {question}\")\n",
    "    return None\n",
    "\n",
    "def build_workflow():\n",
    "    \"\"\"\n",
    "    Build the workflow for the graph\n",
    "    \"\"\"\n",
    "    # Build the nodes\n",
    "    workflow = StateGraph(GraphState)\n",
    "    workflow.add_node(\"db_router_node\", db_router_node)\n",
    "    workflow.add_node(\"general\", general)\n",
    "    workflow.add_node(\"db_query\", database_query)\n",
    "\n",
    "    # Set the entry point\n",
    "    workflow.set_entry_point(\"db_router_node\")\n",
    "\n",
    "    # Build the edges\n",
    "    workflow.add_conditional_edges(\n",
    "        \"db_router_node\",\n",
    "        db_router_edge,\n",
    "        {\n",
    "            \"general\": \"general\",\n",
    "            \"db_query\": \"db_query\",\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"general\", END)\n",
    "    workflow.add_edge(\"db_query\", END)\n",
    "\n",
    "    # Compile the workflow\n",
    "    \n",
    "    local_agent = workflow.compile()\n",
    "\n",
    "    return local_agent\n",
    "\n",
    "def run_agent(query, local_agent, verbose=True):\n",
    "    output = local_agent.invoke({\"query\": query, \"verbose\": verbose})\n",
    "    print(\"=======\")\n",
    "    if output.get('output'):\n",
    "        display(Markdown(output[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n",
      "Step: Routing Query to Database\n",
      "Step: Generating DB Response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 70, offset: 69} for query: \"UNWIND $data AS row MATCH (n:`Document`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'embedding', row.embedding) YIELD node RETURN count(*)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df_cash = df[df['Payment'] == 'Cash']\\ntop_5_sales_cash = df_cash.nlargest(5, 'Total')\\ntop_5_sales_cash[['Invoice ID', 'Total']]\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m      Invoice ID      Total\n",
      "166  234-65-2137  1003.5900\n",
      "357  554-42-2417  1002.1200\n",
      "141  280-17-4359   950.2500\n",
      "941  702-83-5291   943.2990\n",
      "611  277-35-5865   935.2665\u001b[0m\u001b[32;1m\u001b[1;3mThe top 5 supermarket sales amounts paid using cash are as follows:\n",
      "1. Invoice ID: 234-65-2137, Total: $1003.59\n",
      "2. Invoice ID: 554-42-2417, Total: $1002.12\n",
      "3. Invoice ID: 280-17-4359, Total: $950.25\n",
      "4. Invoice ID: 702-83-5291, Total: $943.30\n",
      "5. Invoice ID: 277-35-5865, Total: $935.27\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "=======\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The top 5 supermarket sales amounts paid using cash are as follows:\n",
       "1. Invoice ID: 234-65-2137, Total: $1003.59\n",
       "2. Invoice ID: 554-42-2417, Total: $1002.12\n",
       "3. Invoice ID: 280-17-4359, Total: $950.25\n",
       "4. Invoice ID: 702-83-5291, Total: $943.30\n",
       "5. Invoice ID: 277-35-5865, Total: $935.27"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Hello, how are you?\"\n",
    "query = \"What are the top 5 supermarket sales amount paid using cash?\"\n",
    "agent = build_workflow()\n",
    "run_agent(query, agent, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
